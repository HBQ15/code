"""Generate Katamari daily report emails by processing scanstation logs.

NOTE: This script only goes back 24 hours in the log file.  Log files are
pulled via HTTP from the scanstations. The daily report is generated by
parsing the scanstation logs to find total amount of canceled and completed
scans that are further broken down into specific time ranges.

The script depends on two classes:

1) SBSLogParser: Parses the sbs logs.
2) TimeRange: Stores and manipulates the daily scan data via TimeRange
              objects.

To add another time_range object, add the following line:

TimeRange(start_minute, start_hour, end_hour, end_minute)

to the global list "TIME_RANGES".

If you add another time_range object and it involves altering the
overall time range (i.e. the day now starts at 4 AM or ends at 7 PM),
make sure to edit the global ALL_DAY_TIME_RANGE as well.

NOTE: This script will be managed via crontab.
"""
import datetime
import logging
import socket
import urllib2

import count_3d_scans
import kflags
import sbs_log_parser
import stations
import time_range
import utils

# Default string indicating a scan has started
START_CAPTURE = "configure for capture of type : swivel"
# Default string indiciting a scan has finished
END_CAPTURE = "capture complete"
# Default string indicating a scan has uploaded
UPLOAD_CAPTURE = "uploading to config"
# Default string indicating a karnak error
KARNAK_ERROR = "Unhandled Error"

# List of TimeRange objects
TIME_RANGES = [time_range.TimeRange(5, 0, 10, 0),
               time_range.TimeRange(10, 0, 13, 30),
               time_range.TimeRange(13, 30, 18, 30)]
# This TimeRange object represents the range between the
# first operator shift start time to the end time of the
# last operator shift.
ALL_DAY_TIME_RANGE = time_range.TimeRange(5, 0, 18, 30, True)

FLAGS = kflags.FLAGS

kflags.SetDefaults("stations", type=["prod", "canary", "dev"])
kflags.AddArgument("--log_file", type=str, default="log.txt",
                   help="specify the log filename")


def InitializeDailyData(time_ranges):
  """Initialize the daily_data dictionary.

  Args:
    time_ranges: list of TimeRange objects

  Returns:
    Initialized daily_data dictionary
  """
  daily_data = {}

  # Initialize the daily_data dictionary
  for t in time_ranges:
    daily_data[str(t)] = 0
    daily_data[str(t) + "_canceled"] = 0
    daily_data[str(t) + "_error"] = 0

  # Special case for total
  daily_data["Total"] = 0
  daily_data["Total_canceled"] = 0
  daily_data["Total_error"] = 0

  return daily_data


def UpdateDailyData(log_data, daily_data):
  """Update the daily_data dictionary containing all of the scanstation data.

  Args:
    log_data: the data from one scanstation log file
    daily_data: the dictionary containing all of the scanstation data
  """
  for t in TIME_RANGES:
    completed = str(t)
    canceled = "%s_canceled" % t
    error = "%s_error" % t

    daily_data[completed] += log_data[completed]
    daily_data[canceled] += log_data[canceled]
    daily_data[error] += log_data[error]

  daily_data["Total"] += log_data["Total"]
  daily_data["Total_canceled"] += log_data["Total_canceled"]
  daily_data["Total_error"] += log_data["Total_error"]


def AppendSummary(daily_data, num_of_stations):
  """Generate the title and summary string to append to the html_string.

  Args:
    daily_data: the dictionary containing all of the scanstation data
    num_of_stations: total number of stations anaylzed

  Returns:
    Completed HTML string
  """
  today = datetime.datetime.now().strftime("%A %b-%d-%Y")

  summary = ("Daily Scanstation Report for %s<br><br>\n"
             "==========<br>\n"
             "Daily Summary: 2D Scans<br>\n"
             "<table border='1'>\n"
             "<tr><th></th><th>Completed</th><th>Canceled</th>"
             "<th>Errors</th></tr>" % today)

  # Ensure the Total timerange data is included in the loop
  TIME_RANGES.append("Total")

  for t in TIME_RANGES:
    completed = str(t)
    canceled = "%s_canceled" % t
    error = "%s_error" % t

    summary += ("<tr><td align = center>%s</td>"
                "<td align = center>%s</td>"
                "<td align = center>%s</td>"
                "<td align = center>%s</td></tr>"
                % (t, daily_data[completed], daily_data[canceled],
                   daily_data[error]))

  summary += ("<tr>\n</table><br>\n"
              "Average completed scans per rig: %s <br>\n"
              "==========<br><br>\n"
              % (daily_data["Total"]/num_of_stations))

  return summary


def CreateDailySummaryString(log_file):
  """Create daily summary text file.

  Args:
    log_file: name of the log file on the scanstation

  Returns:
    string containing daily data
  """
  scan_stations = stations.Stations()
  stations_dict = scan_stations.GetStationIPs()
  sorted_stations = stations.GetSortedHostnames(stations_dict)

  daily_data = InitializeDailyData(TIME_RANGES)

  html_string = ""

  for station in sorted_stations:
    logging.debug("Parsing station %s logs", station)
    log_not_found = False

    url = "http://%s:8080/logs/%s" % (stations_dict[station], log_file)

    # If server does not respond in 10 seconds, append error message
    try:
      url_file = urllib2.urlopen(url, timeout=10)
    except urllib2.URLError as url_error:
      logging.error("Log unreachable on %s", station)
      logging.error(url_error)
      log_not_found = True
    except socket.timeout as timeout_error:
      logging.error("Log unreachable on %s", station)
      logging.error(timeout_error)
      log_not_found = True

    if log_not_found:
      html_string += ("Summary: %s <br>"
                      "Log File Not Found/Unreachable<br>"
                      "<b>Note: Station could temporarily be powered "
                      "down for maintenance service.</b><br><br>"
                      % station)
      continue

    ALL_DAY_TIME_RANGE.Reset()
    station_log = sbs_log_parser.SBSLogParser(station, url_file,
                                              ALL_DAY_TIME_RANGE,
                                              START_CAPTURE, END_CAPTURE,
                                              UPLOAD_CAPTURE, KARNAK_ERROR)
    log_data = station_log.GenerateTimeBlockData(TIME_RANGES)

    UpdateDailyData(log_data, daily_data)
    html_string += log_data["html_string"]

  html_string += count_3d_scans.Generate3dHTMLString()

  # Return the title and summary data string
  return AppendSummary(daily_data, len(stations_dict)) + html_string


def main():
  """Create a html string parsed from the station logs and email it."""
  FLAGS.Parse()
  utils.InitializeLogging()

  email_message = CreateDailySummaryString(FLAGS.log_file)

  now = datetime.datetime.now().strftime("%A %b %d %H:%M:%S PDT")
  email_subject = "Daily Scans for %s" % now
  utils.SendEmail(email_subject, email_message)


if __name__ == "__main__":
  main()
